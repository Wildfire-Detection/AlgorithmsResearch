{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OVERVIEW\n",
    "---\n",
    "* Image Preprocessing with OpenCV\n",
    "    * Masking\n",
    "    * Segmentation\n",
    "    * Image Sharpening\n",
    "* Transfer Learning with Keras Pretrained Model\n",
    "* Feature Extraction\n",
    "* Deep Learning Model to Classify the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "\n",
    "import os\n",
    "from keras.applications import xception\n",
    "from keras.preprocessing import image\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import cv2\n",
    "from scipy.stats import uniform\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Masking\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: ../input/keras-pretrained-models/xception*\n"
     ]
    }
   ],
   "source": [
    "#copying the pretrained models to the cache directory\n",
    "cache_dir = os.path.expanduser(os.path.join('~', '.keras'))\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.makedirs(cache_dir)\n",
    "models_dir = os.path.join(cache_dir, 'models')\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "#copy the Xception models\n",
    "!cp ../input/keras-pretrained-models/xception* ~/.keras/models/\n",
    "#show\n",
    "!ls ~/.keras/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_folder = '../input/fire-dataset'\n",
    "data_folder = '../input/fire-dataset/fire_dataset'\n",
    "train_data_folder = '../input/fire-dataset/fire_dataset/fire_images'\n",
    "test_date_folder  = '../input/fire-dataset/fire_dataset/non_fire_images'\n",
    "\n",
    "categories = ['fire_images', 'non_fire_images']\n",
    "len_categories = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_count = {}\n",
    "train_data = []\n",
    "\n",
    "for i , category in tqdm(enumerate(categories)):\n",
    "    class_folder = os.path.join(data_folder, category)\n",
    "    label = category\n",
    "    image_count[category] = []\n",
    "    \n",
    "    for path in os.listdir(os.path.join(class_folder)):\n",
    "        image_count[category].append(category)\n",
    "        train_data.append(['{}/{}'.format(category, path), i, category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#show image count\n",
    "for key, value in image_count.items():\n",
    "    print('{0} -> {1}'.format(key, len(value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#create a dataframe\n",
    "df = pd.DataFrame(train_data, columns=['file', 'id', 'label'])\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMAGE PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#masking function\n",
    "def create_mask_for_plant(image):\n",
    "    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    lower_hsv = np.array([0,0,250])\n",
    "    upper_hsv = np.array([250,255,255])\n",
    "    \n",
    "    mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "#image segmentation function\n",
    "def segment_image(image):\n",
    "    mask = create_mask_for_plant(image)\n",
    "    output = cv2.bitwise_and(image, image, mask = mask)\n",
    "    return output/255\n",
    "\n",
    "#sharpen the image\n",
    "def sharpen_image(image):\n",
    "    image_blurred = cv2.GaussianBlur(image, (0, 0), 3)\n",
    "    image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)\n",
    "    return image_sharp\n",
    "\n",
    "# function to get an image\n",
    "def read_img(filepath, size):\n",
    "    img = image.load_img(os.path.join(data_folder, filepath), target_size=size)\n",
    "    #convert image to array\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHOW SAMPLE IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "nb_rows = 3\n",
    "nb_cols = 5\n",
    "fig, axs = plt.subplots(nb_rows, nb_cols, figsize=(10, 5));\n",
    "plt.suptitle('SAMPLE IMAGES');\n",
    "for i in range(0, nb_rows):\n",
    "    for j in range(0, nb_cols):\n",
    "        axs[i, j].xaxis.set_ticklabels([]);\n",
    "        axs[i, j].yaxis.set_ticklabels([]);\n",
    "        axs[i, j].imshow((read_img(df['file'][np.random.randint(1000)], (255,255)))/255.);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHOW SAMPLE PROCESSED IMAGE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#get an image\n",
    "img = read_img(df['file'][102],(255,255))\n",
    "#mask\n",
    "image_mask = create_mask_for_plant(img)\n",
    "#segmentation\n",
    "image_segmented = segment_image(img)\n",
    "#sharpen the image\n",
    "image_sharpen = sharpen_image(image_segmented)\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 5));\n",
    "plt.suptitle('SAMPLE PROCESSED IMAGE', x=0.5, y=0.8)\n",
    "plt.tight_layout(1)\n",
    "\n",
    "ax[0].set_title('ORIG.', fontsize=12)\n",
    "ax[1].set_title('MASK', fontsize=12)\n",
    "ax[2].set_title('SEGMENTED', fontsize=12)\n",
    "ax[3].set_title('SHARPEN', fontsize=12)\n",
    "\n",
    "\n",
    "ax[0].imshow(img/255);\n",
    "ax[1].imshow(image_mask);\n",
    "ax[2].imshow(image_segmented);\n",
    "ax[3].imshow(image_sharpen);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XCEPTION BOTTLENECK FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE=255\n",
    "\n",
    "##preprocess the input\n",
    "X_train = np.zeros((len(df), INPUT_SIZE, INPUT_SIZE, df.shape[1]), dtype='float')\n",
    "for i, file in tqdm(enumerate(df['file'])):\n",
    "    #read image\n",
    "    img = read_img(file,(INPUT_SIZE,INPUT_SIZE))\n",
    "    #masking and segmentation\n",
    "    image_segmented = segment_image(img)\n",
    "    #sharpen\n",
    "    image_sharpen = sharpen_image(image_segmented)\n",
    "    x = xception.preprocess_input(np.expand_dims(image_sharpen.copy(), axis=0))\n",
    "    X_train[i] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('Train Image Shape: ', X_train.shape)\n",
    "print('Train Image Size: ', X_train.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SPLIT THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y = df['id']\n",
    "train_x, train_val, y_train, y_val = train_test_split(X_train, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('FIRE IMAGES ON TRAINING DATA: ',y_train[y_train==0].shape[0])\n",
    "print('NON-FIRE IMAGES ON TRAINING DATA: ',y_train[y_train==1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "##get the features\n",
    "xception_bf = xception.Xception(weights='imagenet', include_top=False, pooling='avg')\n",
    "bf_train_x = xception_bf.predict(train_x, batch_size=32, verbose=1)\n",
    "bf_train_val = xception_bf.predict(train_val, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#print shape of feature and size\n",
    "print('Train Shape: ', bf_train_x.shape)\n",
    "print('Train Size: ', bf_train_x.size)\n",
    "\n",
    "print('Validation Shape: ', bf_train_val.shape)\n",
    "print('Validation Size: ', bf_train_val.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEEP LEARNING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#keras Sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(units = 256 , activation = 'relu', input_dim=bf_train_x.shape[1]))\n",
    "model.add(Dense(units = 64 , activation = 'relu'))\n",
    "model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'adam' , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#train the model @ 100 epochs\n",
    "history = model.fit(bf_train_x, y_train, epochs=100, batch_size=32);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOSS AND ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(14,5))\n",
    "ax[0].set_title('TRAINING LOSS');\n",
    "ax[1].set_title('TRAINING ACCURACY');\n",
    "\n",
    "\n",
    "ax[0].plot(history.history['loss'], color= 'salmon',lw=2);\n",
    "ax[1].plot(history.history['accuracy'], color= 'green',lw=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#predict the validation data\n",
    "predictions = model.predict_classes(bf_train_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLASSIFICATION REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_val, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "confusion_mat = confusion_matrix(y_val, predictions)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(confusion_mat, square=True, annot=True,\n",
    "            yticklabels=['FIRE_IMG', 'NON_FIRE_IMG'],\n",
    "            xticklabels=['FIRE_IMG', 'NON_FIRE_IMG']);\n",
    "plt.title('CONFUSION MATRIX');\n",
    "plt.xlabel('Y_TRUE');\n",
    "plt.ylabel(\"PREDICTIONS\");"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2798,
     "sourceId": 7251,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 529007,
     "sourceId": 969357,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 29976,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
